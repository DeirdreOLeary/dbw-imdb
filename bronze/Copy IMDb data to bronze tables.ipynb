{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e294ed9-e8a9-49ef-8f87-47c035d34e15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Copy IMDb data from .tsv files to bronze tables\n",
    "## Tables to be copied:\n",
    "- name.basics\n",
    "- title.basics\n",
    "- title.crew\n",
    "- title.episode\n",
    "- title.principals\n",
    "- title.ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "826f77da-593e-467f-9dae-a446ccd1b252",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### name.basics.tsv > name.title_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce0c5870-af8b-4ea6-a843-e2a489e9af13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set variables for the bronze table\n",
    "table_name = 'bronze.name_basics'\n",
    "source_data = '/Volumes/dbw_imdb_01/bronze/20241106/name.basics.tsv'\n",
    "\n",
    "# Drop the table (if it exists) and re-create it - pay attention to the field names, data types and nulls\n",
    "spark.sql(\"DROP TABLE IF EXISTS \" + table_name)\n",
    "\n",
    "spark.sql(\"CREATE TABLE \" + table_name + \" (\" \\\n",
    "  \"nconst STRING NOT NULL, \" + \\\n",
    "  \"primaryName STRING NOT NULL, \" + \\\n",
    "  \"birthYear STRING NOT NULL, \" + \\\n",
    "  \"deathYear STRING NOT NULL, \" + \\\n",
    "  \"primaryProfession STRING NOT NULL, \" + \\\n",
    "  \"knownForTitles STRING NOT NULL)\"\n",
    ")\n",
    "\n",
    "# Copy the data into the table\n",
    "spark.sql(\"COPY INTO \" + table_name + \\\n",
    "  \" FROM '\" + source_data + \"'\" + \\\n",
    "  \" FILEFORMAT = CSV \" + \\\n",
    "  \" FORMAT_OPTIONS ('delimiter' = '\\t',\" + \\\n",
    "        \" 'header' = 'true')\"\n",
    ")\n",
    "\n",
    "# Check a sample of the data to confirm that it has been imported\n",
    "data = spark.sql(\"SELECT * FROM \" + table_name + \" LIMIT 100\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3f66cb0-06e9-4fb9-880a-16284454bdff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### title.basics.tsv > bronze.title_basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73f4e5bf-4eaa-4f2c-9997-2418cf162ff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set variables for the bronze table\n",
    "table_name = 'bronze.title_basics'\n",
    "source_data = '/Volumes/dbw_imdb_01/bronze/20241106/title.basics.tsv'\n",
    "format_option_quote = \"\"  # an extra option is needed for title.basics to handle titles that start but don't end with a double-quote\n",
    "\n",
    "# Drop the table (if it exists) and re-create it - pay attention to the field names, data types and nulls\n",
    "spark.sql(\"DROP TABLE IF EXISTS \" + table_name)\n",
    "\n",
    "spark.sql(\"CREATE TABLE \" + table_name + \" (\" \\\n",
    "  \"tconst STRING NOT NULL, \" + \\\n",
    "  \"titleType STRING NOT NULL, \" + \\\n",
    "  \"primaryTitle STRING NOT NULL, \" + \\\n",
    "  \"originalTitle STRING NOT NULL, \" + \\\n",
    "  \"isAdult STRING NOT NULL, \" + \\\n",
    "  \"startYear STRING NOT NULL, \" + \\\n",
    "  \"endYear STRING NOT NULL, \" + \\\n",
    "  \"runtimeMinutes STRING NOT NULL, \" + \\\n",
    "  \"genres STRING NOT NULL)\"\n",
    ")\n",
    "\n",
    "# Copy the data into the table\n",
    "spark.sql(\"COPY INTO \" + table_name + \\\n",
    "  \" FROM '\" + source_data + \"'\" + \\\n",
    "  \" FILEFORMAT = CSV \" + \\\n",
    "  \" FORMAT_OPTIONS ('delimiter' = '\\t',\" + \\\n",
    "        \" 'header' = 'true',\" + \\\n",
    "        \" 'quote' = '\" + format_option_quote + \"')\"\n",
    ")\n",
    "\n",
    "# Check a sample of the data to confirm that it has been imported\n",
    "data = spark.sql(\"SELECT * FROM \" + table_name + \" LIMIT 100\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cac81d23-74eb-4fad-86ae-08495c60ee46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### title.crew.tsv > bronze.title_crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d5d651c-7d08-4188-aa24-01139e5bf94c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set variables for the bronze table\n",
    "table_name = 'bronze.title_crew'\n",
    "source_data = '/Volumes/dbw_imdb_01/bronze/20241106/title.crew.tsv'\n",
    "\n",
    "# Drop the table (if it exists) and re-create it - pay attention to the field names, data types and nulls\n",
    "spark.sql(\"DROP TABLE IF EXISTS \" + table_name)\n",
    "\n",
    "spark.sql(\"CREATE TABLE \" + table_name + \" (\" \\\n",
    "  \"tconst STRING NOT NULL, \" + \\\n",
    "  \"directors STRING NOT NULL, \" + \\\n",
    "  \"writers STRING NOT NULL)\"\n",
    ")\n",
    "\n",
    "# Copy the data into the table\n",
    "spark.sql(\"COPY INTO \" + table_name + \\\n",
    "  \" FROM '\" + source_data + \"'\" + \\\n",
    "  \" FILEFORMAT = CSV \" + \\\n",
    "  \" FORMAT_OPTIONS ('delimiter' = '\\t',\" + \\\n",
    "        \" 'header' = 'true')\"\n",
    ")\n",
    "\n",
    "# Check a sample of the data to confirm that it has been imported\n",
    "data = spark.sql(\"SELECT * FROM \" + table_name + \" LIMIT 100\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39c951c1-a055-42f4-9935-64fa4b7db066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### title.episode.tsv > bronze.title_episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e6501a-caae-4433-96de-876f08c2a91a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set variables for the bronze table\n",
    "table_name = 'bronze.title_episode'\n",
    "source_data = '/Volumes/dbw_imdb_01/bronze/20241106/title.episode.tsv'\n",
    "\n",
    "# Drop the table (if it exists) and re-create it - pay attention to the field names, data types and nulls\n",
    "spark.sql(\"DROP TABLE IF EXISTS \" + table_name)\n",
    "\n",
    "spark.sql(\"CREATE TABLE \" + table_name + \" (\" \\\n",
    "  \"tconst STRING NOT NULL, \" + \\\n",
    "  \"parentTconst STRING NOT NULL, \" + \\\n",
    "  \"seasonNumber STRING NOT NULL, \" + \\\n",
    "  \"episodeNumber STRING NOT NULL)\"\n",
    ")\n",
    "\n",
    "# Copy the data into the table\n",
    "spark.sql(\"COPY INTO \" + table_name + \\\n",
    "  \" FROM '\" + source_data + \"'\" + \\\n",
    "  \" FILEFORMAT = CSV \" + \\\n",
    "  \" FORMAT_OPTIONS ('delimiter' = '\\t',\" + \\\n",
    "        \" 'header' = 'true')\"\n",
    ")\n",
    "\n",
    "# Check a sample of the data to confirm that it has been imported\n",
    "data = spark.sql(\"SELECT * FROM \" + table_name + \" LIMIT 100\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b36d1883-4503-4051-9ba6-dbdeede6bfca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### title.principals.tsv > bronze.title_principals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "793adae0-4663-4def-89b6-1ef39d72e38d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set variables for the bronze table\n",
    "table_name = 'bronze.title_principals'\n",
    "source_data = '/Volumes/dbw_imdb_01/bronze/20241106/title.principals.tsv'\n",
    "\n",
    "# Drop the table (if it exists) and re-create it - pay attention to the field names, data types and nulls\n",
    "spark.sql(\"DROP TABLE IF EXISTS \" + table_name)\n",
    "\n",
    "spark.sql(\"CREATE TABLE \" + table_name + \" (\" \\\n",
    "  \"tconst STRING NOT NULL, \" + \\\n",
    "  \"ordering STRING NOT NULL, \" + \\\n",
    "  \"nconst STRING NOT NULL, \" + \\\n",
    "  \"category STRING NOT NULL, \" + \\\n",
    "  \"job STRING NOT NULL, \" + \\\n",
    "  \"characters STRING NOT NULL)\"\n",
    ")\n",
    "\n",
    "# Copy the data into the table\n",
    "spark.sql(\"COPY INTO \" + table_name + \\\n",
    "  \" FROM '\" + source_data + \"'\" + \\\n",
    "  \" FILEFORMAT = CSV \" + \\\n",
    "  \" FORMAT_OPTIONS ('delimiter' = '\\t',\" + \\\n",
    "        \" 'header' = 'true')\"\n",
    ")\n",
    "\n",
    "# Check a sample of the data to confirm that it has been imported\n",
    "data = spark.sql(\"SELECT * FROM \" + table_name + \" LIMIT 100\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e94371f0-63c9-4f7c-bfce-31dfbe2726ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### title.ratings.tsv > bronze.title_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be4d5b8d-f122-43ea-a6d8-dfaeca67bb00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set variables for the bronze table\n",
    "table_name = 'bronze.title_ratings'\n",
    "source_data = '/Volumes/dbw_imdb_01/bronze/20241106/title.ratings.tsv'\n",
    "\n",
    "# Drop the table (if it exists) and re-create it - pay attention to the field names, data types and nulls\n",
    "spark.sql(\"DROP TABLE IF EXISTS \" + table_name)\n",
    "\n",
    "spark.sql(\"CREATE TABLE \" + table_name + \" (\" \\\n",
    "  \"tconst STRING NOT NULL, \" + \\\n",
    "  \"averageRating STRING NOT NULL, \" + \\\n",
    "  \"numVotes STRING NOT NULL)\"\n",
    ")\n",
    "\n",
    "# Copy the data into the table\n",
    "spark.sql(\"COPY INTO \" + table_name + \\\n",
    "  \" FROM '\" + source_data + \"'\" + \\\n",
    "  \" FILEFORMAT = CSV \" + \\\n",
    "  \" FORMAT_OPTIONS ('delimiter' = '\\t',\" + \\\n",
    "        \" 'header' = 'true')\"\n",
    ")\n",
    "\n",
    "# Check a sample of the data to confirm that it has been imported\n",
    "data = spark.sql(\"SELECT * FROM \" + table_name + \" LIMIT 100\")\n",
    "display(data)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Copy IMDb data to bronze tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
